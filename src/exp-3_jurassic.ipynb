{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "import ai21\n",
    "ai21.api_key = 'keys_here'\n",
    "seed = 13\n",
    "pairs_num = 4\n",
    "model_name = 'jurassic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "\n",
    "df_test = pd.read_csv(\"../dataset/test.csv\", encoding=\"utf-8\")\n",
    "df_train = pd.read_csv('../dataset/train.csv', encoding='utf-8')\n",
    "test_dataset = df_test[\"question\"]\n",
    "label_dataset = df_test[\"label\"]\n",
    "train_dataset = df_train['question']\n",
    "answer_dataset = df_train['answer']\n",
    "\n",
    "test_list = []\n",
    "label_list = []\n",
    "for question, label in zip(test_dataset, label_dataset):\n",
    "    test_list.append(question)\n",
    "    label_list.append(label)\n",
    "\n",
    "\n",
    "prompt = \"\"\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will say \"tricky question.\" first and give the reason, otherwise I will say \"true question.\" first and give the reason.\"\"\"\n",
    "prompt_list = []\n",
    "sample_string = ''\n",
    "pos_ids = random.sample(range(int(len(train_dataset) / 2)), pairs_num)\n",
    "neg_ids = [num + int(len(train_dataset) / 2) for num in pos_ids]\n",
    "pos_questions = [train_dataset[id] for id in pos_ids]\n",
    "neg_questions = [train_dataset[id] for id in neg_ids]\n",
    "pos_answers = [answer_dataset[id] for id in pos_ids]\n",
    "neg_answers = [answer_dataset[id] for id in neg_ids]\n",
    "\n",
    "\n",
    "for pos_q, neg_q, pos_a, neg_a in zip(pos_questions, neg_questions, pos_answers, neg_answers):\n",
    "    sample_string += f'\\n\\nQ: {pos_q}\\nA:tricky question. {pos_a}\\n\\nQ: {neg_q}\\nA:true question. {neg_a}'\n",
    "for question in test_list:\n",
    "    processed_string = f\"{prompt}{sample_string}\\n\\nQ: {question}\\nA:\"\n",
    "    prompt_list.append(processed_string)\n",
    "\n",
    "\n",
    "print(\"length of prompt_list: \" + str(len(prompt_list)))\n",
    "print()\n",
    "print('prompt and sample string: ')\n",
    "print(prompt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "                \"numResults\": 1,\n",
    "                \"maxTokens\": 32,\n",
    "                \"topKReturn\": 0,\n",
    "                \"temperature\": 0.0,\n",
    "                \"topP\": 1,\n",
    "                \"countPenalty\": {\n",
    "                    \"scale\": 0,\n",
    "                    \"applyToNumbers\": False,\n",
    "                    \"applyToPunctuations\": False,\n",
    "                    \"applyToStopwords\": False,\n",
    "                    \"applyToWhitespaces\": False,\n",
    "                    \"applyToEmojis\": False\n",
    "                },\n",
    "                \"frequencyPenalty\": {\n",
    "                    \"scale\": 0,\n",
    "                    \"applyToNumbers\": False,\n",
    "                    \"applyToPunctuations\": False,\n",
    "                    \"applyToStopwords\": False,\n",
    "                    \"applyToWhitespaces\": False,\n",
    "                    \"applyToEmojis\": False\n",
    "                },\n",
    "                \"presencePenalty\": {\n",
    "                    \"scale\": 0,\n",
    "                    \"applyToNumbers\": False,\n",
    "                    \"applyToPunctuations\": False,\n",
    "                    \"applyToStopwords\": False,\n",
    "                    \"applyToWhitespaces\": False,\n",
    "                    \"applyToEmojis\": False\n",
    "                },\n",
    "                \"stopSequences\": [\"\\n\"]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "response_list = []\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in prompt_list[count:]:\n",
    "    response = ai21.Completion.execute(model=\"j1-jumbo\", prompt=prompt, **payload)\n",
    "    response_list.append(response)\n",
    "    count += 1\n",
    "    time.sleep(1)\n",
    "    if count % 200 == 0:\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)\n",
    "print(len(response_list))\n",
    "print([response_list[count - 1]['completions'][0]['data']['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_response_list = []\n",
    "for response in response_list:\n",
    "    new_response_list.append(response.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../output/exp-3/incontext/exp-3_jurrasic_scale-{pairs_num}_{model_name}_{time_stamp}_{str(seed)}.json\", \"a\") as f:\n",
    "    for i in range(len(new_response_list)):\n",
    "        new_response_list[i][\"question\"] = test_list[i]\n",
    "        new_response_list[i][\"label\"] = label_list[i]\n",
    "    json.dump(new_response_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../output/exp-3/incontext/exp-3_jurrasic_scale-{pairs_num}_{model_name}_{time_stamp}_{str(seed)}.json\", \"r\") as f:\n",
    "    output_dict = {'question': [], 'answer': [], 'label': []}\n",
    "    data = json.load(f)\n",
    "    for response in data:\n",
    "        label = response['label']\n",
    "        question = response['question']\n",
    "        answer = response['completions'][0]['data']['text']\n",
    "        output_dict['label'].append(label)\n",
    "        output_dict['question'].append(question)\n",
    "        output_dict['answer'].append(answer.replace(\"\\n\", ''))\n",
    "df = pd.DataFrame(output_dict)\n",
    "df.to_csv(f\"../output/exp-3/incontext/exp-3_jurrasic_scale-{pairs_num}_{model_name}_{time_stamp}_{str(seed)}.csv\")\n",
    "print('result saved in ' + f\"../output/exp-3/incontext/exp-3_jurrasic_scale-{pairs_num}_{model_name}_{time_stamp}_{str(seed)}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:16:26) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0d97bcb8eb2c5c8bf713bbf333656d5333558e3a67524bffa742df36669829f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
